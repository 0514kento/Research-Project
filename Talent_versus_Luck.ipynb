{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57921df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Agent: \n",
    "    def __init__(self, x, y, talent, square_size, learning_rate, discount_factor):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.talent = talent\n",
    "        self.capital = 10\n",
    "        self.green_hits = 0\n",
    "        self.red_hits = 0\n",
    "        self.square_size = square_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.Q = {}\n",
    "\n",
    "    def choose_action(self, epsilon):\n",
    "        state = (self.x, self.y)\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action = random.choice([\"up\", \"down\", \"right\", \"left\"])\n",
    "        else:\n",
    "            if state in self.Q:\n",
    "                if False:  #エラーが出るので保留\n",
    "                    action = random.choice([\"up\", \"down\", \"right\", \"left\"])\n",
    "                    maxq = self.Q[state][action]\n",
    "                    for a in self.Q[state]:\n",
    "                        if maxq < self.Q[state][a]:\n",
    "                            action = a\n",
    "                            maxq = self.Q[state][a]\n",
    "                else:\n",
    "                    action = max(self.Q[state], key=self.Q[state].get)\n",
    "            else:\n",
    "                action = random.choice([\"up\", \"down\", \"right\", \"left\"])\n",
    "        return action\n",
    "\n",
    "    def get_next_position(self, action):\n",
    "        #next_x, next_y = self.x, self.y\n",
    "        if action == \"up\":\n",
    "            self.y = (self.y + 1) % self.square_size\n",
    "            self.x = self.x\n",
    "        elif action == \"down\":\n",
    "            self.y = (self.y - 1) % self.square_size\n",
    "            self.x = self.x\n",
    "        elif action == \"left\":\n",
    "            self.x = (self.x - 1) % self.square_size\n",
    "            self.y = self.y\n",
    "        elif action == \"right\":\n",
    "            self.x = (self.x + 1) % self.square_size\n",
    "            self.y = self.y\n",
    "        return self.x, self.y\n",
    "    \n",
    "    #def get_q_table(self):\n",
    "       # return self.Q\n",
    "\n",
    "class Simulation:\n",
    "    def __init__(self, square_size, num_agents, num_moves, num_green_balls, num_red_balls, num_multiple, learning_rate, discount_factor, epsilon):\n",
    "        self.square_size = square_size\n",
    "        self.num_agents = num_agents\n",
    "        self.num_moves = num_moves\n",
    "        self.num_green_balls = num_green_balls\n",
    "        self.num_red_balls = num_red_balls\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_factor = discount_factor\n",
    "        self.epsilon = epsilon\n",
    "        self.agents = []\n",
    "        self.green_balls = []\n",
    "        self.red_balls = []\n",
    "        self.num_multiple = num_multiple\n",
    "\n",
    "    def initialize_agents(self, position_only = False, position_capital_only = False):\n",
    "        if position_only:\n",
    "            for _ in range(self.num_agents):\n",
    "                self.agents[_].x = np.random.randint(self.square_size)\n",
    "                self.agents[_].y = np.random.randint(self.square_size)\n",
    "        elif position_capital_only:\n",
    "            for _ in range(self.num_agents):\n",
    "                self.agents[_].x = np.random.randint(self.square_size)\n",
    "                self.agents[_].y = np.random.randint(self.square_size)\n",
    "                self.agents[_].capital = 10\n",
    "        else:\n",
    "            for _ in range(self.num_agents):\n",
    "                x = np.random.randint(self.square_size)\n",
    "                y = np.random.randint(self.square_size)\n",
    "                talent = np.random.normal(0.6, 0.1)\n",
    "                agent = Agent(x, y, talent, self.square_size, self.learning_rate, self.discount_factor)\n",
    "                self.agents.append(agent)\n",
    "\n",
    "    def initialize_balls(self):\n",
    "        for _ in range(self.num_green_balls):\n",
    "            x = np.random.randint(self.square_size)\n",
    "            y = np.random.randint(self.square_size)\n",
    "            self.green_balls.append((x, y))\n",
    "        for _ in range(self.num_red_balls):\n",
    "            x = np.random.randint(self.square_size)\n",
    "            y = np.random.randint(self.square_size)\n",
    "            self.red_balls.append((x, y))\n",
    "            \n",
    "            \n",
    "    def get_q_tables(self):\n",
    "        a_to_int = {'up':0, 'down':1, 'left':2, 'right':3}\n",
    "        q_tables = np.zeros((self.square_size, self.square_size, 4))\n",
    "        for agent in self.agents:\n",
    "            for position in agent.Q:\n",
    "                for action in agent.Q[position]:\n",
    "                    q_tables[position[0], position[1], a_to_int[action]] += agent.Q[position][action]\n",
    "        return q_tables / self.num_agents\n",
    "\n",
    "            \n",
    "\n",
    "    def run_simulation(self):\n",
    "        self.initialize_agents()\n",
    "        self.initialize_balls()\n",
    "\n",
    "        for agent in self.agents:\n",
    "            for x in range(self.square_size):\n",
    "                for y in range(self.square_size):\n",
    "                    #agent.Q[(x, y)] = {\"up\": 0, \"down\": 0, \"left\": 0, \"right\": 0}  # 行動価値関数の初期化\n",
    "                    agent.Q[(x, y)] = {\"up\": np.random.rand()/10000, \"down\": np.random.rand()/10000, \"left\": np.random.rand()/10000, \"right\": np.random.rand()/10000}  # 行動価値関数の初期化\n",
    "\n",
    "        # Training (40 episodes)\n",
    "        agentlog_train = []\n",
    "        for _ in range(self.num_moves * 40):\n",
    "            #self.initialize_agents(position_only=True)\n",
    "            for k, agent in enumerate(self.agents):\n",
    "                agent.learning_rate = np.random.rand() * self.learning_rate \n",
    "                #agent.learning_rate = np.random.normal(self.learning_rate / 2, 0.005)\n",
    "                state = (agent.x, agent.y)\n",
    "                action = agent.choose_action(self.epsilon)\n",
    "                next_x, next_y = agent.get_next_position(action)\n",
    "                next_state = (next_x, next_y)\n",
    "                green_hit = (next_x, next_y) in self.green_balls  # グリーンボールに当たるか判定\n",
    "                red_hit = (next_x, next_y) in self.red_balls  # レッドボールに当たるか判定\n",
    "\n",
    "                # ボールに当たった場合の報酬とQ値の更新\n",
    "                reward = 0 \n",
    "                if green_hit:\n",
    "                    if agent.talent >= np.random.random():\n",
    "                        reward = agent.capital / 10**4\n",
    "                        #reward = 1\n",
    "                        agent.capital *= self.num_multiple\n",
    "                if red_hit:\n",
    "                        agent.capital /= self.num_multiple\n",
    "                        reward = -agent.capital / 10**4\n",
    "                        #reward = -1\n",
    "\n",
    "                \n",
    "\n",
    "                # Q値の更新\n",
    "                if state in agent.Q:\n",
    "                    if next_state not in agent.Q:\n",
    "                        agent.Q[next_state] = {\"up\": 0, \"down\": 0, \"left\": 0, \"right\": 0}# 新しい状態のQ値を初期化\n",
    "                    max_q = agent.Q[next_state][max(agent.Q[next_state], key=agent.Q[next_state].get)]\n",
    "                    agent.Q[state][action] += agent.learning_rate * (reward + agent.discount_factor * max_q - agent.Q[state][action])\n",
    "                    \n",
    "                agentlog_train.append([_, k, agent.x, agent.y])\n",
    "        agentlog_train = pd.DataFrame(columns=['t', 'a', 'x', 'y'], data=np.array(agentlog_train, dtype=int))\n",
    "\n",
    "        # Reset agents' capital\n",
    "        for agent in self.agents:\n",
    "            agent.capital = 10\n",
    "\n",
    "        # Test (1 episode)\n",
    "        self.initialize_agents(position_capital_only=True)\n",
    "        agentlog_test = []\n",
    "        for _ in range(self.num_moves):\n",
    "            for k, agent in enumerate(self.agents):\n",
    "                state = (agent.x, agent.y)\n",
    "                action = agent.choose_action(self.epsilon)\n",
    "                next_x, next_y = agent.get_next_position(action)\n",
    "                next_state = (next_x, next_y)\n",
    "                green_hit = (next_x, next_y) in self.green_balls  # グリーンボールに当たるか判定\n",
    "                red_hit = (next_x, next_y) in self.red_balls  # レッドボールに当たるか判定\n",
    "\n",
    "                # ボールに当たった場合の報酬とQ値の更新\n",
    "                if green_hit:\n",
    "                    if agent.talent >= np.random.random():\n",
    "                        agent.capital *= self.num_multiple\n",
    "                        agent.green_hits += 1\n",
    "                if red_hit:\n",
    "                        agent.capital /= self.num_multiple\n",
    "                        agent.red_hits += 1\n",
    "\n",
    "                #reward = agent.capital  # 報酬は資本の変化\n",
    "\n",
    "                # Q値の更新\n",
    "                #if state in agent.Q:\n",
    "                    #if next_state not in agent.Q:\n",
    "                        #agent.Q[next_state] = {\"up\": 0, \"down\": 0, \"left\": 0, \"right\": 0}  # 新しい状態のQ値を初期化\n",
    "                    #max_q = max(agent.Q[state], key=agent.Q[state].get)\n",
    "                    #agent.Q[state][action] += agent.learning_rate * (reward + agent.discount_factor * agent.Q[next_state][max_q] - agent.Q[state][action])\n",
    "                agentlog_test.append([_, k, agent.x, agent.y])\n",
    "        agentlog_test = pd.DataFrame(columns=['t', 'a', 'x', 'y'], data=np.array(agentlog_test, dtype=int))\n",
    "        return agentlog_train, agentlog_test\n",
    "\n",
    "    def save_results_to_csv(self, filename):\n",
    "        results = {'Agent': [], 'Learning_Rate': [],'Capital': [], 'Talent': [], 'Green Hits': [], 'Red Hits': []}\n",
    "        for i, agent in enumerate(self.agents):\n",
    "            results['Agent'].append(i + 1)\n",
    "            results['Learning_Rate'].append(agent.learning_rate)\n",
    "            results['Capital'].append(agent.capital)\n",
    "            results['Talent'].append(agent.talent)\n",
    "            results['Green Hits'].append(agent.green_hits)\n",
    "            results['Red Hits'].append(agent.red_hits)\n",
    "\n",
    "        df = pd.DataFrame(results)\n",
    "        df.to_csv(filename, index=False)\n",
    "\n",
    "    def visualize_results(self):\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        for agent in self.agents:\n",
    "            plt.scatter(agent.x, agent.y, color='blue', marker='*', alpha=0.6, s=100)\n",
    "\n",
    "        for ball in self.green_balls:\n",
    "            plt.scatter(ball[0], ball[1], color='green', marker='o', alpha=0.6, s=50)\n",
    "        for ball in self.red_balls:\n",
    "            plt.scatter(ball[0], ball[1], color='red', marker='o', alpha=0.6, s=50)\n",
    "\n",
    "        plt.xlim(0, self.square_size)\n",
    "        plt.ylim(0, self.square_size)\n",
    "        plt.title('Agent and Ball Positions')\n",
    "        plt.xlabel('X')\n",
    "        plt.ylabel('Y')\n",
    "        plt.show()\n",
    "\n",
    "# シミュレーションの実行と結果の保存\n",
    "simulation = Simulation(square_size=25, num_agents=1000, num_moves=80, num_green_balls=50, num_red_balls=50, num_multiple = 1.2, learning_rate=0.02, discount_factor=0.9, epsilon=0.1)\n",
    "agentlog_train, agentlog_test = simulation.run_simulation()\n",
    "simulation.save_results_to_csv('simulation_results_rl.csv')\n",
    "simulation.visualize_results()\n",
    "q_tables = simulation.get_q_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13885532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_capital_highest_agent(times):\n",
    "    df_high = pd.DataFrame()\n",
    "    for i in range(times):\n",
    "        if i%10==0:print(f'time:{i}')\n",
    "        simulation = Simulation(square_size=25, num_agents=1000, num_moves=80, num_green_balls=50, num_red_balls=50, num_multiple = 1.2, learning_rate=0.005, discount_factor=0.9, epsilon=0.1)\n",
    "        agentlog_train, agentlog_test = simulation.run_simulation()\n",
    "        simulation.save_results_to_csv('simulation_results_rl.csv')\n",
    "        df = pd.read_csv('simulation_results_rl.csv')\n",
    "        \n",
    "        a = df[['Talent', 'Capital', 'Learning_Rate']].loc[df.nlargest(1,'Capital').index]\n",
    "        list_ = [[a['Learning_Rate'].iloc[-1], a['Capital'].iloc[-1], a['Talent'].iloc[-1]]]\n",
    "        \n",
    "        \n",
    "        df_new = pd.DataFrame(list_, columns=['Learning_rate', 'Capital', 'Talent'])\n",
    "        df_high = pd.concat([df_high, df_new])\n",
    "    \n",
    "    return df_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ced3dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_highest = gain_capital_highest_agent(10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
